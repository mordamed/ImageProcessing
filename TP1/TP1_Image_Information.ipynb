{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Information\n",
    "\n",
    "The main objectives of this module are:\n",
    "\n",
    "* Manipulate an image with Python, scikit-image and numpy.\n",
    "* Process images at the pixel level.\n",
    "* Compute and understand image histograms.\n",
    "* Understand lossless compression & reconstruction.\n",
    "* Understand the co-occurrence matrix.\n",
    "* Use different colour representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read & write an image\n",
    "\n",
    "In this exercise, we will simply open an image file, display it, and save a copy. \n",
    "\n",
    "**Use the [scikit-image io](https://scikit-image.org/docs/dev/api/skimage.io.html) module to open, show & save a copy of the \"camera.jpg\"**\n",
    "\n",
    "*Note: we use the **%matplotlib inline** command to display the image in the notebook. It would not be necessary if you execute the code in the terminal or in a standard IDE like PyCharm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/tajani/Documents/Codes/image_processing/TP1-Image Information-20250927/data/camera.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m imread, imsave, imshow\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m imgCamera = \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/camera.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m imshow(imgCamera)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/skimage/_shared/utils.py:328\u001b[39m, in \u001b[36mdeprecate_parameter.__call__.<locals>.fixed_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.new_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    325\u001b[39m         \u001b[38;5;66;03m# Assign old value to new one\u001b[39;00m\n\u001b[32m    326\u001b[39m         kwargs[\u001b[38;5;28mself\u001b[39m.new_name] = deprecated_value\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/skimage/io/_io.py:82\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(fname, as_gray, plugin, **plugin_args)\u001b[39m\n\u001b[32m     79\u001b[39m         plugin = \u001b[33m'\u001b[39m\u001b[33mtifffile\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname, _hide_plugin_deprecation_warnings():\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     img = \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimread\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[33m'\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/skimage/_shared/utils.py:538\u001b[39m, in \u001b[36mdeprecate_func.__call__.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    536\u001b[39m stacklevel = \u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.get_stack_length(func) - stack_rank\n\u001b[32m    537\u001b[39m warnings.warn(message, category=\u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=stacklevel)\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/skimage/io/manage_plugins.py:254\u001b[39m, in \u001b[36mcall_plugin\u001b[39m\u001b[34m(kind, *args, **kwargs)\u001b[39m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[32m    252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCould not find the plugin \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimread\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     out = np.asarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out.flags[\u001b[33m'\u001b[39m\u001b[33mWRITEABLE\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     13\u001b[39m         out = out.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/imageio/v3.py:53\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     51\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m] = index\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(img_file.read(**call_kwargs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/imageio/core/imopen.py:113\u001b[39m, in \u001b[36mimopen\u001b[39m\u001b[34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m     request.format_hint = format_hint\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     request = \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m source = \u001b[33m\"\u001b[39m\u001b[33m<bytes>\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/imageio/core/request.py:249\u001b[39m, in \u001b[36mRequest.__init__\u001b[39m\u001b[34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Codes/image_processing/TP1-Image Information-20250927/.venv/lib/python3.12/site-packages/imageio/core/request.py:409\u001b[39m, in \u001b[36mRequest._parse_uri\u001b[39m\u001b[34m(self, uri)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[32m    407\u001b[39m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(fn):\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo such file: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % fn)\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    411\u001b[39m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[32m    412\u001b[39m     dn = os.path.dirname(fn)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No such file: '/home/tajani/Documents/Codes/image_processing/TP1-Image Information-20250927/data/camera.png'"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave, imshow\n",
    "%matplotlib inline\n",
    "\n",
    "imgCamera = imread('data/camera.jpg')\n",
    "imshow(imgCamera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try the same with \"view.jpg\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you open an image with scikit-image, it is stored as a Numpy [ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) object. Numpy arrays are objects which can be easily manipulated for numerical computations.\n",
    "\n",
    "**Using *ndarray* methods & attributes, answer the following questions about the \"camera\" and \"view\" images:**\n",
    "\n",
    "1. What is the shape of the image? (width & height)\n",
    "1. What is the minimum pixel value? What is the maximum pixel value?\n",
    "1. What is the data type for each pixel?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## -- Your code here -- ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in image shape between a camera.jpg and an view.jpg. The shape of the ndarray show the layers of the matrix. The first two numbers are length and width, and the third number (i.e. 3 in view.jpg) is for three layers: Red, Green, Blue. So, camera.jpg has only one channel making it a greyscale image and view.jpg an RGB image. \n",
    "\n",
    "The data type of pixel value is the same for both the images - uint8 which means that the value of each pixel is an 8-bit unsigned integer and the value cannot be outside of the 0 to 255 range.\n",
    "For a grey scale image 0 corresponds to black pixel value and 255 to white pixel value and the numbers in between have correspond to varying shades of grey.\n",
    "The red, green and blue use 8 bits each, which have integer values from 0 to 255. This makes 256x256x256=16777216 possible colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual information that is stored in an image is the \"value\" of each pixel. With the above information, try to show the pixel values at different spots in the images, for example the camera's coat, sky in both the images, and the hot air balloon from view.jpg.\n",
    "Also try to show only a 100x100 pixels window taken at the center of the image, head of the cameraman and a single hot air balloon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [Image I/O](https://www.youtube.com/watch?v=rgJmji4rTpw&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=1)\n",
    "* [Image data type & color channels](https://www.youtube.com/watch?v=rIO1EJ--yeg&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image histograms\n",
    "\n",
    "### Compute and plot the histogram and the normalized histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Computer image analysis is about finding ways to use that \"raw\" information in order to extract \"processed\" information : what is in the image?\n",
    "\n",
    "Image histograms are one of the simplest ways of looking at the information contained in an image. An image histogram is made by simply counting the number of pixels that have a given value. The length of the histogram will therefore correspond to the number of possible values in an image (in this case, 256).\n",
    "\n",
    "You can use the [pyplot module](https://matplotlib.org/api/pyplot_api.html) from matplotlib to display plots & histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets have a look at the images as arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, camera.jpg is a 2D array with the grayscale values of each pixel, whereas view.jpg is a 3D array with red, blue and green values ranging from 0 to 255.\n",
    "We can use the pyplot module from matplotlib to display the image with more options on the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testimg1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m      3\u001b[39m plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.imshow(\u001b[43mtestimg1\u001b[49m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mCameraman\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.show()\n",
      "\u001b[31mNameError\u001b[39m: name 'testimg1' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testimg1)\n",
    "plt.title(\"Cameraman\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testimg2)\n",
    "plt.title(\"View\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera man image is not true to its original colours, why does it look like that?\n",
    "\n",
    "When you give a grayscale image to matplotlib, it uses a default colormap that is not necessarily \"grayscale\" to display the information. We can force it to display the image correctly by using the cmap parameter. We can also increase the size of the figure, hide the axis, and make sure that the scale is correct for the values (0 = black, 255 = white), as by default matplotlib uses the lowest value in the image as black and the highest as white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(testimg1, cmap=plt.cm.gray, vmin=0, vmax=255)\n",
    "plt.title(\"Cameraman\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plotting the histogram**\n",
    "\n",
    "Now there are different ways to get the histogram for the greyscale and RGB images.\n",
    "\n",
    "First let's work with the greyscale image (camera.jpg). \n",
    "\n",
    "We can use the histogram function from numpy, but let's first try to code it ourselves.\n",
    "We need to :\n",
    "1. Create a 256-length vector filled with 0s to initialize the histogram\n",
    "2. For each value between 0 and 255, count how many pixels in the image have that value and put it in the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 256-length vector filled with 0s\n",
    "hist = np.zeros((256,)).astype('int')\n",
    "print(\"Empty histogram\")\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you use the histogram to answer the following questions ? (you don't need to code anything here)\n",
    "\n",
    "1. What is the average gray value of the cameraman ?\n",
    "1. What is the average gray value of the sky ?\n",
    "1. Is there more 'cameraman' pixels than 'sky' pixels ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value between 0 and 255 (python's range(a,b) translates to [a,b])\n",
    "for v in range(0,256):\n",
    "    hist[v] = (im==v).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line is a bit more complex, but it shows how powerful numpy can be for arrays operations. (im==v) does an element-wise comparison between the array im and the scalar v (the value we are looking at). It will create a new array of the same size as im, and fill it with True (1) wherever the pixel value of im was equal to v and with False (0) everywhere else.\n",
    "\n",
    "Then, the sum function will sum all values of this new array. This counts the number of pixels with that particular value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the histogram #\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, instead of using this raw histogram, we will use the **\"normalized histogram\"**, which looks exactly the same except that we want the sum of all values to be equal to 1 (the histogram will therefore become like a probability distribution that a pixel in the image has a given value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the histogram #\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the histogram method from numpy, but make sure to check the documentation on how to use it properly. Numpy's histogram method expects a flat vector, not a 2D image. Also, the \"bins\" of the histogram have to be specified, and the way they work is not necessarily intuitive: the numpy method is generalized so that it can work on float data and not just on integers, so the bins are defined by intervals rather than the discrete sampling that we've done above. There are multiple options for defining the intervals:\n",
    "\n",
    "If you pass an integer to the \"bins\" parameter, numpy will divide the image range in that number of equally spaced bins. Note that if you do that on an image that doesn't start at 0 or end at 255 (for instance, and over- or under-exposed image), it will not give you the \"correct\" intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = testimg1.copy()\n",
    "im2 = np.maximum(im2, 10) # set all pixels with value < 10 to 10.  \n",
    "hist_np, bins = np.histogram(im2.flatten(), bins=256)\n",
    "print(bins[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can define the intervals yourself using a range, but here you should be aware of the (sometimes unexpected) behaviour of the method. If you have a range [0, 1, 2, 3], the histogram will contain 3 bins: [0, 1], [1, 2], and [2, 3], with the last bin including the last item in the range. In that case, if we have an integer image, the last bin would contain both the im==2 and the im==3 pixels! We can see this behaviour in action if we try to use a range (256):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = testimg1.copy()\n",
    "im2 = np.maximum(im2, 10) # set all pixels with value < 10 to 10.  \n",
    "hist_np, bins = np.histogram(im2.flatten(), bins=256)\n",
    "print(bins[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the histogram is a length-255 vector instead of 256, and if we compare to the one we computed manually, the last two bins have been put together. So if we want to reproduce the histogram we had before, we need to use a range(257), so that the last bin contains the interval [255, 256], correctly matching the im==255 bin !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the histogram #\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Now what can we do with this information?**\n",
    "\n",
    "We can see that there are two great \"peaks\" : at around 15 (which would be almost black), and at around 160 (which is light gray). It seems like a reasonable guess to say that those values are mostly the cameraman's black coat, and the sky, which are both very homogeneous regions with a lot of pixels of the same color.\n",
    "\n",
    "To check that, we could try to quickly segment the image using this information. Let's look at the image of all pixels between 10 and 20, and all pixels between 155 and 165:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_image = (im<=20)*(im>=10)\n",
    "light_image = (im<=165)*(im>=155)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1) # Subplots can show multiple images on the same figure.\n",
    "plt.imshow(dark_image, cmap=plt.cm.gray)\n",
    "plt.title('Cameraman?')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(light_image, cmap=plt.cm.gray)\n",
    "plt.title('Sky?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too bad, but clearly we don't have all of the sky. We can in fact see in our histogram that the peak is wider for the sky than for the cameraman. Let's try to find better values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve the threshold #\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's far from perfect but it's good enough for now. But with this, try to answer these questions :\n",
    "\n",
    "The average gray value of the cameraman is around 15.\n",
    "The average gray value of the sky is around 165."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The peak of the cameraman is higher than the peak of the sky, but the peak of the sky is wider. To know if there is more in one or the other, we have to compute the sum of those regions of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the number of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to indicate that there are more pixels in the sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plotting the cummulative histogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative histogram is a mapping that counts the cumulative number of pixel intensity values in all ofthe bins up to the current bin.\n",
    "The cumulative histogram of a histogram is defined as : \n",
    "\n",
    "$Ci = \\sum_{j=0}^i h_j$\n",
    "\n",
    "The cumulative histogram is useful for some imageoperations that use histograms: such as Image histogram equalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and plot the **cumulated histogram**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cumulative histogram\n",
    "## -- Your code here -- ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [Computing a greyscale histogram](https://www.youtube.com/watch?v=g6hkHQbwB0I&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=3)\n",
    "* [Numpy arrays: operations, indexing, masking](https://www.youtube.com/watch?v=rPNTkrM2dZw&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=4&t=253s)\n",
    "* [Normalized and cumulative histograms](https://www.youtube.com/watch?v=uCgu0-KZt1o&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Analysis of RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by having a look at the immunohistochemistry image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import immunohistochemistry\n",
    "\n",
    "im = immunohistochemistry()\n",
    "print(im.shape)\n",
    "print(im.min(),im.max())\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen with the view.jpg image, the immunohistochemistry image also has dimensions of 512x512 pixels, with 3 8-bits channels (values between 0 and 255).\n",
    "\n",
    "We want to isolate the \"brown cells\" in the RGB and HSV space. To see what we are dealing with, it would be interesting to first have a look at the histograms for the different channels. Let's start in RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the RGB channel of the the image #\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 3 histograms have a similar shape, with 3 distinct peaks. \n",
    "\n",
    "Let's try to find out exactly where they are by finding the local maxima (that I'll define here as \"higher value than anything in a size-10 neighbourhood and >= than 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peak values #\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could a good \"brown candidate\" be with those values? \n",
    "\n",
    "If we look at the pixels at the top-left corner of the image, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closest peaks to those values would be red=157, green=127, blue=95, which would be a bit brighter on average. This makes sense: the top-left corner is a darker brown than most brown pixels in the image.\n",
    "\n",
    "Let's use [157,127,95] as our \"brown\" reference.\n",
    "\n",
    "If we represent each color as a point in (R,G,B) space, we can compute an euclidian \"color distance\" between a pixel and this brown reference as :\n",
    "\n",
    "$d_{colour} = \\sqrt{(R-R_{ref})^2 + (G-G_{ref}) + (B-B_{ref})^2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to visualize this using mplot3d. Each point in the  scatterplot below is a pixel from the image, set in the RGB space. The larger point is the \"reference brown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_brown = np.array([157.,127.,95.])\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "pixels = im.reshape((im.shape[0]*im.shape[1],3))[::10,:] # we take 1/10th of the pixels, because otherwise it takes too long to render.\n",
    "col = np.zeros((pixels.shape[0],4)) # we create a RGBA array so that we can give transparency to the points and better see everything\n",
    "col[:,:3] = pixels/255\n",
    "col[:,3] = 0.1\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pixels[:,0], pixels[:,1], pixels[:,2], s=2, c=col)\n",
    "ax.scatter(ref_brown[0],ref_brown[1],ref_brown[2],s=50,c=[ref_brown/255])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image processing measuring and valuing a distance between two points is important. \n",
    "The Euclidean distance tools describe each cell's relationship to a source or a set of sources based on the straight-line distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Eucledian distance #\n",
    "# Eucledian distance = sqrt( sum( difference^2 ) )\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the histogram of the \"distance\" image to see if we can find a threhold that looks interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few possible candidates : right after the left peak (~30), somewhere in the down-slope (~50), at the low point in the middle (~120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one doesn't look bad. There is still a lot of confusion between the brown and the blue, however. In RGB space, it will be difficult to do better.\n",
    "\n",
    "Let's now look at the hsv color-space to see if it might be easier to analyze the image there. We first need to convert the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv\n",
    "\n",
    "hsv = rgb2hsv(im)\n",
    "\n",
    "# Covert to HSV-space #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hue is normally expressed as an angle (in radian or degrees), but is here encoded as a float between 0 and 1. To show the histogram, we can simply multiply that number by 360 to \"convert\" it to degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a very sharp peak in the colour space. Let's find its value, and see what the \"distance map\" looks like, and how it compares to the distance in RGB space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the histograms of the distances :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a much sharper peak in Hue space, which means that the brown pixels tend to be much \"closer\" together. This is normal, as in HSV space the differences in \"saturation\" and \"value\" (which can be seen as the color-to-gray scale and the light-to-dark scale) are independant from the differences in hue (the color-to-color scale).\n",
    "\n",
    "This means that a \"light brown\" and a \"dark brown\", which can be very different in RGB space, will be very close together in Hue space. Let's try to find a good threshold for the Hue distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are still some problems, with pixels from the background which are seen as brown. That's because those pixels are fully saturated (completely gray), which means that their hue is mostly random. We can easily get rid of them by adding a threshold on the the saturation channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize those results, we can use the segmentation as a mask to remove all non-brown pixels and compare the HSV and RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mask #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the HSV results are much better, as the color information is encoded in a way that makes it easier to use. RGB color space is a good way to encode the information for display (as it directly relates to the way the screen will show it), but isn't always very practical for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [RGB vs HSV](https://www.youtube.com/watch?v=oVpSTZtZQNM&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=10)\n",
    "* [Distances: image space and colour space](https://www.youtube.com/watch?v=f6aJJldc38E&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=11)\n",
    "* [Creating a Magic Wand](https://www.youtube.com/watch?v=Aw--_cJ7o5I&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image entropy\n",
    "\n",
    "The \"entropy\" of a signal, in information theory, can generally be interpreted as the \"number of bits required to encode the signal\". It is a measure of the \"amount of information\" contained in the signal. Intuitively, a signal with a very narrow distribution (all values are close to each other) will have a very low entropy, while a signal with a wide distribution (the values are evenly distributed) will have a higher entropy.\n",
    "\n",
    "\n",
    "### **1. Compute the image entropy of the camera.jpg image.** \n",
    "\n",
    "The image entropy is given by:\n",
    "           \n",
    "$e = - \\sum_{g=0}^N p(g) \\log_2(p(g))$ \n",
    "\n",
    "where $p(g)$ is the probability that a pixel has the grayscale value g, and N is the number of possible grayscale values. Note that $p(g)$ is directly given by the normalized histogram.\n",
    "\n",
    "The entropy is generally computed using the base 2 logarithm, so that we can give it the information theory interpretation of \"number of bits per element\" necessary to encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread,imsave,imshow\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Compute the entropy #\n",
    "\n",
    "\n",
    "## -- Your code here -- ##\n",
    "\n",
    "def entropy (im):\n",
    "    #compute normalized histogram -> p(g)\n",
    "    # ## -- Your code here -- ##\n",
    "\n",
    "    #compute the entropy e\n",
    "    ## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy will be higher when you have an even distribution of grayscale vale, and lower if the image is more homogeneous. We can look at the extreme cases of a completely random image, and of a uniform image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (np.random.random((100,100))*255).astype('uint8')\n",
    "B = np.zeros((100,100))\n",
    "print(\"Entropy of a random image :\", entropy(norm_hist(A)))\n",
    "print(\"Entropy of a uniform image :\", entropy(norm_hist(B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A truly uniform distribution would have an entropy of 8 (which corresponds to the number of bits per pixels necessary to encode the information), while a uniform image has an entropy of 0.\n",
    "\n",
    "Now let's apply this to the cameraman:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the entropy for camera.jpg\n",
    "    ## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. What is the entropy of a shuffled version of the cameraman?**\n",
    "\n",
    "As the entropy is computed on the histogram of the image, it doesn't take into account any sort of spatial information. If we shuffle the cameraman image randomly, it may seems like we produce a \"random\" image, but the entropy is exactly the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's easier to shuffle the image if it's first flattened in 1D\n",
    "\n",
    "## -- Your code here -- ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [Computing the image entropy](https://www.youtube.com/watch?v=L2VtGt2FsRQ&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image compression\n",
    "\n",
    "Using the code below as a starting point:\n",
    "\n",
    "- **Decompose an image** by recursively subsampling its dimensions and computing the remainders, such that each level of recursion performs the following operation:\n",
    "\n",
    "![ ](image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling is a way of reducing the size of an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage.io import imread\n",
    "\n",
    "# Modify this method:\n",
    "def split(im):\n",
    "    a = im[0:-1:2,0:-1:2]\n",
    "    b = im[0:-1:2,1::2]\n",
    "    c = im[1::2,0:-1:2]\n",
    "    d = im[1::2,1::2]\n",
    "    \n",
    "    R = np.vstack((np.hstack((a,b)),np.hstack((c,d))))\n",
    "    return R\n",
    "\n",
    "im = imread('camera.jpg').astype(np.int16) # cast the camera image as a signed integer to avoid overflow\n",
    "s = split(im)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "# interpolation='nearest' -> don't try to interpolate values between pixels if the size of the display is different from the size of the image\n",
    "# cmap=cm.gray -> display in grayscale\n",
    "# vmin=-255 -> set \"black\" as -255\n",
    "# vmax=255 -> set \"white\" as 255\n",
    "plt.imshow(s,interpolation='nearest',cmap=cm.gray,vmin=-255, vmax=255)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute how the image entropy evolves** with regards to the level of decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy will tend to be higher when we have a flatter histogram, and it will be lower when we have narrow peaks\n",
    "#the idea here is that pixels that are very close together in the image will tend to have very similar value; borders not included\n",
    "\n",
    "\n",
    "# -- Your code here -- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily observe that the entropy has gone down quite a bit, which was our goal, without losing any information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rebuild the original image** from the pyramid (allowing the selection the level of recursion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Your code here -- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [Subsampling and rescaling](https://www.youtube.com/watch?v=rYNUby5bIlA&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=7)\n",
    "* [Pyramid compression](https://www.youtube.com/watch?v=yrsyF8T5OAU&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Co-occurrence matrix\n",
    "\n",
    "While the histogram of an image is independent of the position of the pixels, the co-occurrence matrix gives us information about their spatial distribution.\n",
    "\n",
    "A co-occurrence matrix is computed for a given displacement, looking at the pair of values spatially separated by that displacement. The co-occurrence matrix is a square matrix, its size given by the number of possible values that a pixels can take in the image.\n",
    "\n",
    "1. Compute de [cooccurrence matrix](https://en.wikipedia.org/wiki/Co-occurrence_matrix) for a chosen displacement $(\\Delta x,\\Delta y)$ (see [greycomatrix](http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.greycomatrix) in scikit-image)\n",
    "1. What is the entropy of the cooccurrence matrix ?\n",
    "1. How does this entropy evolve if we increase the displacement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import graycomatrix\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "\n",
    "# -- Your code here -- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, short distances have most of the values of the co-occurence matrix close to the diagonal. This means that pixels that are close spatially tend to also have similar values. If we look at a longer distance, we will see a flatter distribution, and therefore a higher entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need more help? You can check the following videos:**\n",
    "\n",
    "* [Grayscale co-occurence matrix](https://www.youtube.com/watch?v=cq0Br3zB2AU&list=PLI3XOM9BWLSW6vTPxc9ZfSABS31o7HMub&index=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Project - Watermark\n",
    "\n",
    "Write code to automatically add a watermark to a photograph.\n",
    "\n",
    "![ ](wm_proj.jpg)\n",
    "\n",
    "## Main requirements\n",
    "\n",
    "The minimum requirements are to:\n",
    "* Add the white pixels from the watermark somewhere in the photograph.\n",
    "* Save the resulting image as an image file & display it in the notebook\n",
    "\n",
    "You may use the *watermark.png* file available in the GitHub repository, or choose/create your own.\n",
    "\n",
    "## Additional requirements\n",
    "\n",
    "(note: this is not an exhaustive list, use your imagination!)\n",
    "\n",
    "* Add an option to choose the watermark location\n",
    "* Add transparency effect to the watermark\n",
    "* Determine if the watermark should be dark or light based on the luminosity of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Your code here -- #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
